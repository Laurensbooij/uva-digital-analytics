{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges for week 2\n",
    "\n",
    "Now that we've seen how Python and Jupyter Notebooks work and that you have read about Digital Analytics and Computational Social Science, it's time for you to combine apply this knowledge. This week has three challenges. \n",
    "\n",
    "Each challenge has three components:\n",
    "1. **Programming**: Applying one of the programming or data analysis steps in Python you learned in the tutorial\n",
    "2. **Interpretation**: Explaining what you are doing and interpreting the results of the data analysis in MarkDown \n",
    "3. **Reflection**: Connecting these concepts with the literature of the week in a short reflection (*max 300 words*)\n",
    "\n",
    "**Some important notes for the challenges:**\n",
    "1. These challenges are a warming up, and help you get ready for class. Make sure to give them a try on all of them. If you get an error message, try to troubleshoot it (using Google often helps). If all else fails, go to the next challenge (but make sure to hand it in).\n",
    "2. While we of course like when you get all the answers right, the important thing is to exercise and apply the knowledge. So we will still accept challenges that may not be complete, as long as we see enough effort *for each challenge*. The rubric (see Canvas) reflects this.\n",
    "3. Delivering the challenge on time on Canvas assignment is critical, as it helps also prepare for the DA live session. Check on Canvas how to hand it in.\n",
    "\n",
    "### Facing issues? \n",
    "\n",
    "We are constantly monitoring the issues on the GitHub to help you out. Don't hesitate to log an issue there, explaining well what the problem is, showing the code you are using, and the error message you may be receiving. \n",
    "\n",
    "**Important:** We are only monitoring the repository in weekdays, from 9.30 to 17.00. Issues logged after this time will most likely be answered the next day. This means you should not wait for our response before submitting a challenge :-)\n",
    "\n",
    "\n",
    "## Challenge 1\n",
    "\n",
    "\n",
    "### Programming challenge\n",
    "\n",
    "Collect Twitter data using ```twarc``` if you have the developer credentials approved (see the Twitter API training details on Canvas) or request Twitter data to the lecturers (see Canvas) and use that file. Load that file using ```pandas``` and:\n",
    "1. Display the first 5 rows\n",
    "2. Check which columns the dataframe contains\n",
    "3. Check which columns have missing values\n",
    "4. Check how many tweets are available in the dataset\n",
    "5. Calculate the average and the standard deviation of retweets and favorites\n",
    "6. Calculate the average, minimum and maximum number of followers that users in the dataset have\n",
    "7. Indicate the most popular languages in the dataset\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "Write a **technical** and a **business** summary for your dataset, aimed at a stakeholder in an organization. \n",
    "\n",
    "* The **technical** summary should contain some specifications about the dataset (e.g., how it was collected, what tool was used, its length, presence of missing values, columns contained etc.). \n",
    "* The **business** summary should contain information relevant to a stakeholder (e.g., metrics such as retweets, favorites, information about the languages or users).\n",
    "\n",
    "Use Markdown formatting to make the summary clear and visually appealing, and constantly refer to the output of the code to substantiate your claims. If needed, you can combine the code with the summary (e.g., start the summary in markdown, run the relevant code in the next cell, and interpret the output using MarkDown in the next cell).\n",
    "\n",
    "### Reflection\n",
    "\n",
    "Wagner et al. (2021) discuss a set of important challenges for measurement in what they call *algorithmically infused societies*. Select one relevant challenge that they discuss in their text, and relate to the Twitter data you have just loaded and reviewed. How are the measures that you have just reported to stakeholders (in the interpretation section) affected by this challenge? Please motivate your response, and be as specific as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2\n",
    "\n",
    "### Programming challenge\n",
    "\n",
    "Download your own data from a digital platform in **JSON** or **CSV** format. You can use Facebook or Instagram data (which make the data available almost immediately), or other platforms (e.g., Google, TikTok, Spotify etc.) - but be mindful of how much time the platform says they will take to make the data available to you.\n",
    "\n",
    "Download the data in your computer, and select one of the files that has advertising-related data (or profile interests) - but **not** your posts, personal, or network (friends or followers).\n",
    "\n",
    "After finding this file, move it to the appropriate folder where you are running the notebook. Load it in Pandas and: \n",
    "\n",
    "1. Display the first 5 rows\n",
    "2. Check with columns the dataframe contains\n",
    "3. Check which columns have missing values\n",
    "4. Summarize the information for at least one column (if it is numeric, descriptive statistics should do, if it is categorical or text, then counting frequencies and showing the top 5 items is enough).\n",
    "\n",
    "**Note:** as shown in the videos, sometimes you may need to apply the function ```expand_dictionary``` to get meaningful data. We will cover this in more detail on DA3. If the function does not work, log an issue on GitHub with the problem (if there's still time before the submission) or select a different file in your data download package. \n",
    "\n",
    "### Interpretation\n",
    "\n",
    "Write a **technical** and a **personal** summary for your dataset. \n",
    "\n",
    "* The **technical** summary should contain some specifications about the dataset (e.g., how it was collected, what tool was used, its length, presence of missing values, columns contained etc.). \n",
    "* The **personal** summary should contain an explanation of what the dataset contains (e.g., related to advertising), and how it relates (or not) to your online behavior.\n",
    "\n",
    "Use Markdown formatting to make the summary clear and visually appealing, and constantly refer to the output of the code to substantiate your claims. If needed, you can combine the code with the summary (e.g., start the summary in markdown, run the relevant code in the next cell, and interpret the output using MarkDown in the next cell).\n",
    "\n",
    "### Reflection\n",
    "\n",
    "Salz & Dewar (2019) discuss a set of important chalenges in their proposed ethics framework. Imagine that you will conduct a research project and ask multiple respondents to donate their platform usage data to you. Please select two challenges from those suggested by the authors, and explain how these challenges relate to doing research using these data donations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3\n",
    "\n",
    "### Programming challenge\n",
    "\n",
    "We will run sentiment analysis on the tweets collected via the Twitter API next week. This week you therefore need to **request** the sentiment analysis to us. \n",
    "\n",
    "Using the dataset from challenge 1, you need to:\n",
    "1. Select only tweets that have language set to English (i.e., ```en```)\n",
    "2. Select only the columns ```id``` and ```text```\n",
    "\n",
    "After slicing the dataframe following the needs above you need to:\n",
    "1. Save the results to a pickle file containing your name, and the language of the tweets (in ISO two-letter codes). In my case, it would be:\n",
    "    * **TheoAraujo_EN.pkl**\n",
    "2. Upload our OneDrive folder (see Canvas: [Requesting sentiment analysis](https://canvas.uva.nl/courses/24065/pages/requesting-sentiment-analysis))\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "Explain to another student in your own words, how they can slice a dataframe based on columns or on rows - and how this can be useful for data analysis. Make sure to provide detailed, step-by-step explanations.\n",
    "\n",
    "### Reflection\n",
    "\n",
    "For challenges 1, 2 and 3, you have done many data science activities, from collecting tweets or your own data, loading the data, inspecting and even requesting sentiment analysis. Using the CRISP-DM explanation found in Larose 2014, provide a short overview of the actions you took, and to which step(s) of the CRISP-DM process they belong. Motivate your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
